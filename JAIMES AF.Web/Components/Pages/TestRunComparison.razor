@page "/admin/test-runs/compare"
@rendermode InteractiveServer

@using MattEland.Jaimes.ServiceDefinitions.Responses
@using MattEland.Jaimes.Web.Components.Shared

@inject HttpClient Http
@inject ILoggerFactory LoggerFactory
@inject NavigationManager NavigationManager
@inject ISnackbar Snackbar
@using MattEland.Jaimes.Web.Components.Helpers

<PageTitle>Test Run Comparison</PageTitle>

<MudContainer MaxWidth="MaxWidth.ExtraLarge" Class="mt-4">
    <CompactHeroSection Title="Test Run Comparison"
                        Icon="@Icons.Material.Filled.Compare"
                        Theme="CompactHeroSection.HeroTheme.Info"
                        ActionText="@(_versionResults.Count > 0 && !string.IsNullOrEmpty(Executions) ? "View Report" : null)"
                        ActionIcon="@Icons.Material.Filled.Visibility"
                        OnActionClick="ViewCombinedReport">
        <SubtitleContent>
            @if (_versionResults.Count > 0)
            {
                <span>Comparing @_versionResults.Count version@(_versionResults.Count != 1 ? "s" : "") across @_testCaseIds.Count test case@(_testCaseIds.Count != 1 ? "s" : "")</span>
            }
            else
            {
                <span>Compare test results across agent versions</span>
            }
        </SubtitleContent>
    </CompactHeroSection>

    <MudBreadcrumbs Items="_breadcrumbs" Separator=">" Class="mb-4"></MudBreadcrumbs>

    @if (_isLoading)
    {
        <div style="display: flex; justify-content: center; align-items: center; min-height: 200px;">
            <MudProgressCircular Indeterminate="true"/>
        </div>
    }
    else if (_versionResults.Count == 0)
    {
        @* Enhanced Empty State *@
        <div class="glass-card pa-6" style="text-align: center;">
            <MudStack AlignItems="AlignItems.Center" Spacing="3">
                <MudIcon Icon="@Icons.Material.Filled.Compare" Color="Color.Info"
                         Style="font-size: 4rem; opacity: 0.5;"/>
                <MudText Typo="Typo.h6">No test results to compare</MudText>
                <MudText Class="text-muted mb-4">Run tests on different agent versions to compare results here.</MudText>
                <MudButton Variant="Variant.Filled" Color="Color.Success" Size="Size.Large"
                           Href="/admin/run-tests" StartIcon="@Icons.Material.Filled.PlayArrow">
                    Run Tests
                </MudButton>
            </MudStack>
        </div>
    }
    else
    {
        @* Aggregate Summary Stats Row - Matching AgentStats.razor pattern *@
        <MudGrid Spacing="3" Class="mb-4" Style="display: flex; align-items: stretch;">
            @* Versions Card *@
            <MudItem xs="12" sm="6" md="2" Style="flex: 1; display: flex;">
                <div class="stat-card stat-card-info"
                     style="width: 100%; height: 100px; display: flex; flex-direction: column; justify-content: center;">
                    <MudText Typo="Typo.caption" Class="text-muted">Versions</MudText>
                    <MudStack Row="true" AlignItems="AlignItems.Center" Spacing="1">
                        <MudIcon Icon="@Icons.Material.Filled.Compare" Size="Size.Small" Color="Color.Info" />
                        <MudText Typo="Typo.h6" Style="font-weight: 600; color: var(--mud-palette-primary);">
                            @_versionResults.Count
                        </MudText>
                    </MudStack>
                </div>
            </MudItem>

            @* Test Cases Card *@
            <MudItem xs="12" sm="6" md="2" Style="flex: 1; display: flex;">
                <MudLink Href="/admin/test-cases" Underline="Underline.None" Style="width: 100%; display: flex;">
                    <div class="stat-card stat-card-success"
                         style="cursor: pointer; width: 100%; height: 100px; display: flex; flex-direction: column; justify-content: center;">
                        <MudText Typo="Typo.caption" Class="text-muted">Test Cases</MudText>
                        <MudStack Row="true" AlignItems="AlignItems.Center" Spacing="1">
                            <MudIcon Icon="@Icons.Material.Filled.Science" Size="Size.Small" Color="Color.Success" />
                            <MudText Typo="Typo.h6" Style="font-weight: 600; color: var(--mud-palette-primary);">
                                @_testCaseIds.Count
                            </MudText>
                        </MudStack>
                    </div>
                </MudLink>
            </MudItem>

            @* Metrics Card with Pie Chart *@
            <MudItem xs="12" sm="6" md="3" Style="flex: 1.5; display: flex;">
                <div class="stat-card @GetOverallScoreClass()"
                     style="width: 100%; height: 100px; display: flex; flex-direction: column; justify-content: center;">
                    <MudText Typo="Typo.caption" Class="text-muted">Metrics</MudText>
                    <MudStack Row="true" AlignItems="AlignItems.Center" Spacing="2">
                        <EvaluationProgressRing Size="32"
                            TotalSegments="@_metricNames.Count"
                            Metrics="@GetAggregatedMetrics()" />
                        <MudText Typo="Typo.body2" Style="font-weight: 600; color: var(--mud-palette-primary);">
                            @(GetOverallAverageScore()?.ToString("F2") ?? "-") Avg Score
                        </MudText>
                    </MudStack>
                </div>
            </MudItem>
        </MudGrid>

        @* Grouping Toggle *@
        <MudStack Row="true" AlignItems="AlignItems.Center" Spacing="2" Class="mb-3">
            <MudText Typo="Typo.overline" 
                     Style="letter-spacing: 1.5px; color: #7B2CBF; font-weight: 600;">
                METRICS COMPARISON
            </MudText>
            <MudSpacer />
            <ViewModeToggle TValue="string" 
                           @bind-Value="_groupBy" 
                           Options="@_viewModeOptions" />
            @if (!string.IsNullOrEmpty(Executions))
            {
                <MudButton Variant="Variant.Text"
                           Color="Color.Default"
                           StartIcon="@Icons.Material.Filled.List"
                           Href="/admin/test-reports">
                    All Reports
                </MudButton>
            }
        </MudStack>

        @* Hierarchical Grid *@
        <MudPaper Class="pa-3" Elevation="2">
            @if (_groupBy == "agent")
            {
                @foreach (var vr in _versionResults)
                {
                    <div class="mb-6">
                        <MudStack Row="true" AlignItems="AlignItems.Center" Spacing="2" Class="mb-2">
                            <AgentVersionDisplay 
                                AgentId="@vr.AgentId" 
                                AgentName="@vr.AgentName" 
                                VersionId="@vr.InstructionVersionId"
                                VersionNumber="@vr.VersionNumber" />
                            @if (vr.AvgScore.HasValue)
                            {
                                <MudChip T="string" Size="Size.Small" 
                                         Color="@MetricColorHelper.GetScoreColor(vr.AvgScore.Value)">
                                    @vr.AvgScore.Value.ToString("F2") avg
                                </MudChip>
                            }
                        </MudStack>
                        <ComparisonMatrix TRow="TestCaseRunResponse" TColumn="string"
                                         Rows="@vr.Runs.OrderBy(r => r.TestCaseId)"
                                         Columns="@_metricNames"
                                         RowLabel="@(r => r.TestCaseName ?? $"Test Case {r.TestCaseId}")"
                                         RowLabelHref="@(r => $"/admin/test-cases/{r.TestCaseId}")"
                                         ColumnHeader="@(c => c)"
                                         CellValue="@((r, c) => r.Metrics?.FirstOrDefault(m => m.MetricName == c)?.Score)"
                                         CellTooltip="@((r, c) => GetMetricTooltip(c, r.Metrics?.FirstOrDefault(m => m.MetricName == c)))"
                                         CellStyle="@((r, c, v) => GetHeatmapCellStyle(v))"
                                         AverageValue="@(r => r.Metrics?.Any() == true ? r.Metrics.Average(m => m.Score) : null)"
                                         ShowTimeColumn="true"
                                         TimeValue="@(r => r.DurationMs)"
                                         RowHeaderLabel="Test Case">
                            <RowIndicator>
                                <EvaluationProgressRing Size="20"
                                    TotalSegments="@_metricNames.Count"
                                    Metrics="@GetRunMetrics(context)" />
                            </RowIndicator>
                        </ComparisonMatrix>
                    </div>
                }
            }
            else
            {
                @* Grouped by Test Case: each test case is a section, rows are agent versions *@
                @foreach (var testCaseId in _testCaseIds)
                {
                    var testCaseName = GetTestCaseName(testCaseId);
                    var runsForTestCase = GetRunsForTestCase(testCaseId);
                    <div class="mb-6">
                        <MudStack Row="true" AlignItems="AlignItems.Center" Spacing="2" Class="mb-2 mt-3">
                            <MudIcon Icon="@Icons.Material.Filled.Science" Size="Size.Small" Color="Color.Info" />
                            <MudLink Href="@($"/admin/test-cases/{testCaseId}")" 
                                     Typo="Typo.subtitle1" 
                                     Style="font-weight: 600;">
                                @testCaseName
                            </MudLink>
                        </MudStack>
                        <ComparisonMatrix TRow="VersionRunPair" TColumn="string"
                                         Rows="@runsForTestCase"
                                         Columns="@_metricNames"
                                         RowLabel="@(r => $"{r.Version.AgentName} v{r.Version.VersionNumber}")"
                                         ColumnHeader="@(c => c)"
                                         CellValue="@((r, c) => r.Run?.Metrics?.FirstOrDefault(m => m.MetricName == c)?.Score)"
                                         CellTooltip="@((r, c) => GetMetricTooltip(c, r.Run?.Metrics?.FirstOrDefault(m => m.MetricName == c)))"
                                         CellStyle="@((r, c, v) => GetHeatmapCellStyle(v))"
                                         AverageValue="@(r => r.Run?.Metrics?.Any() == true ? r.Run.Metrics.Average(m => m.Score) : null)"
                                         ShowTimeColumn="true"
                                         TimeValue="@(r => r.Run?.DurationMs)"
                                         RowHeaderLabel="Agent Version">
                            <RowIndicator>
                                @if (context.Run != null)
                                {
                                    <EvaluationProgressRing Size="20"
                                        TotalSegments="@_metricNames.Count"
                                        Metrics="@GetRunMetrics(context.Run)" />
                                }
                            </RowIndicator>
                            <RowLabelContent>
                                @if (context.Run != null)
                                {
                                    <AgentVersionDisplay 
                                        AgentId="@context.Version.AgentId" 
                                        AgentName="@context.Version.AgentName" 
                                        VersionId="@context.Version.InstructionVersionId"
                                        VersionNumber="@context.Version.VersionNumber" />
                                }
                                else
                                {
                                    <MudStack Row="true" AlignItems="AlignItems.Center">
                                        <AgentVersionDisplay 
                                            AgentId="@context.Version.AgentId" 
                                            AgentName="@context.Version.AgentName" 
                                            VersionId="@context.Version.InstructionVersionId"
                                            VersionNumber="@context.Version.VersionNumber" />
                                        <MudText Class="text-muted ml-2">(No run)</MudText>
                                    </MudStack>
                                }
                            </RowLabelContent>
                        </ComparisonMatrix>
                    </div>
                }
            }
        </MudPaper>
    }
</MudContainer>

@* Report Dialog *@
<MudDialog @bind-Visible="_showReportDialog" Options="_reportDialogOptions">
    <TitleContent>
        <MudText Typo="Typo.h6">Combined Test Report</MudText>
    </TitleContent>
    <DialogContent>
        @if (_loadingReport)
        {
            <MudStack AlignItems="AlignItems.Center" Spacing="2">
                <MudProgressCircular Indeterminate="true"/>
                <MudText>Loading report...</MudText>
            </MudStack>
        }
        else if (!string.IsNullOrEmpty(_reportError))
        {
            <MudAlert Severity="Severity.Error">@_reportError</MudAlert>
        }
        else if (!string.IsNullOrEmpty(_reportHtml))
        {
            <iframe srcdoc="@_reportHtml" style="width: 100%; height: 70vh; border: none;"></iframe>
        }
    </DialogContent>
    <DialogActions>
        <MudButton Color="Color.Default" OnClick="@(() => _showReportDialog = false)">Close</MudButton>
    </DialogActions>
</MudDialog>

@code {
    [SupplyParameterFromQuery]
    [Parameter] public string? Executions { get; set; }

    private List<VersionResult> _versionResults = [];
    private List<int> _testCaseIds = [];
    private List<string> _metricNames = [];
    private string _groupBy = "agent";

    private static readonly ViewModeToggle<string>.ViewModeOption<string>[] _viewModeOptions =
    [
        new("agent", "Group by Agent", Icons.Material.Filled.SmartToy),
        new("testcase", "Group by Test Case", Icons.Material.Filled.Science)
    ];

    private DialogOptions _reportDialogOptions = new()
    {
        MaxWidth = MaxWidth.ExtraExtraLarge,
        FullWidth = true
    };

    private bool _isLoading = true;
    private bool _showReportDialog;
    private bool _loadingReport;
    private string? _reportHtml;
    private string? _reportError;

    private List<BreadcrumbItem> _breadcrumbs = new()
    {
        new BreadcrumbItem("Home", href: "/"),
        new BreadcrumbItem("Admin", href: "/admin"),
        new BreadcrumbItem("Test Cases", href: "/admin/test-cases"),
        new BreadcrumbItem("Comparison", href: null, disabled: true)
    };

    protected override async Task OnInitializedAsync()
    {
        if (string.IsNullOrEmpty(Executions))
        {
            _isLoading = false;
            return;
        }

        var executionNames = Executions.Split(',', StringSplitOptions.RemoveEmptyEntries | StringSplitOptions.TrimEntries);
        var allRuns = new List<TestCaseRunResponse>();

        // Collect all runs from all execution names
        foreach (var execName in executionNames)
        {
            try
            {
                var runs = await Http.GetFromJsonAsync<List<TestCaseRunResponse>>(
                    $"test-case-runs?executionName={Uri.EscapeDataString(execName)}");

                if (runs != null && runs.Count > 0)
                {
                    allRuns.AddRange(runs);
                }
            }
            catch (Exception ex)
            {
                var logger = LoggerFactory.CreateLogger<TestRunComparison>();
                logger.LogError(ex, "Failed to load runs for execution {ExecutionName}", execName);
            }
        }

        // Group runs by (AgentId, InstructionVersionId) to properly separate different versions
        var grouped = allRuns
            .GroupBy(r => (r.AgentId ?? "", r.InstructionVersionId))
            .ToList();

        foreach (var group in grouped)
        {
            var runs = group.ToList();
            var firstRun = runs[0];
            _versionResults.Add(new VersionResult
            {
                ExecutionName = firstRun.ExecutionName ?? "",
                AgentId = firstRun.AgentId ?? "",
                AgentName = firstRun.AgentName ?? "Unknown",
                InstructionVersionId = firstRun.InstructionVersionId,
                VersionNumber = firstRun.VersionNumber ?? "Unknown",
                Runs = runs,
                AvgDuration = runs.Where(r => r.DurationMs.HasValue).Select(r => r.DurationMs!.Value).DefaultIfEmpty(0).Average(),
                AvgScore = runs.SelectMany(r => r.Metrics ?? []).Select(m => m.Score).DefaultIfEmpty().Average()
            });

            foreach (var run in runs)
            {
                if (run.Metrics != null)
                {
                    foreach (var metric in run.Metrics)
                    {
                        if (!_metricNames.Contains(metric.MetricName))
                        {
                            _metricNames.Add(metric.MetricName);
                        }
                    }
                }
            }
        }

        _testCaseIds = _versionResults.SelectMany(vr => vr.Runs.Select(r => r.TestCaseId)).Distinct().OrderBy(id => id).ToList();
        _metricNames = _metricNames.OrderBy(m => m).ToList();

        _isLoading = false;
    }

    private string GetTestCaseName(int testCaseId)
    {
        var run = _versionResults.SelectMany(vr => vr.Runs).FirstOrDefault(r => r.TestCaseId == testCaseId);
        return run?.TestCaseName ?? $"Test Case {testCaseId}";
    }

    private List<VersionRunPair> GetRunsForTestCase(int testCaseId)
    {
        return _versionResults.Select(vr => new VersionRunPair
        {
            Version = vr,
            Run = vr.Runs.FirstOrDefault(r => r.TestCaseId == testCaseId)
        }).ToList();
    }

    private static string? GetMetricTooltip(string metricName, TestCaseRunMetricResponse? metric)
    {
        if (metric == null) return null;
        if (string.IsNullOrWhiteSpace(metric.Remarks))
        {
            return $"{metricName}: {metric.Score:F2}";
        }
        return $"{metricName}: {metric.Score:F2}\n\nReasoning: {metric.Remarks}";
    }

    /// <summary>
    /// Get aggregated metrics across all runs for the overall pie chart
    /// </summary>
    private List<MessageEvaluationMetricResponse> GetAggregatedMetrics()
    {
        return _metricNames.Select(name => new MessageEvaluationMetricResponse
        {
            MetricName = name,
            Score = GetAverageScoreForMetric(name) ?? 0 // Already on 0-5 scale from test metrics
        }).ToList();
    }

    /// <summary>
    /// Get average score for a specific metric across all runs (0-1 scale)
    /// </summary>
    private double? GetAverageScoreForMetric(string metricName)
    {
        var scores = _versionResults
            .SelectMany(vr => vr.Runs)
            .SelectMany(r => r.Metrics ?? [])
            .Where(m => m.MetricName == metricName)
            .Select(m => m.Score)
            .ToList();

        return scores.Any() ? scores.Average() : null;
    }

    /// <summary>
    /// Get metrics for a specific version (for pie chart display)
    /// </summary>
    private List<MessageEvaluationMetricResponse> GetVersionMetrics(VersionResult vr)
    {
        return _metricNames.Select(name =>
        {
            var avgScore = vr.Runs
                .SelectMany(r => r.Metrics ?? [])
                .Where(m => m.MetricName == name)
                .Select(m => m.Score)
                .DefaultIfEmpty(0)
                .Average();

            return new MessageEvaluationMetricResponse
            {
                MetricName = name,
                Score = avgScore // Already on 0-5 scale from test metrics
            };
        }).ToList();
    }

    /// <summary>
    /// Get metrics for a specific test case run (for row pie chart display)
    /// </summary>
    private List<MessageEvaluationMetricResponse> GetRunMetrics(TestCaseRunResponse run)
    {
        return _metricNames.Select(name =>
        {
            var score = run.Metrics?.FirstOrDefault(m => m.MetricName == name)?.Score ?? 0;

            return new MessageEvaluationMetricResponse
            {
                MetricName = name,
                Score = score // Already on 0-5 scale from test metrics
            };
        }).ToList();
    }

    /// <summary>
    /// Get overall average score across all versions and metrics
    /// </summary>
    private double? GetOverallAverageScore()
    {
        var allScores = _versionResults
            .SelectMany(vr => vr.Runs)
            .SelectMany(r => r.Metrics ?? [])
            .Select(m => m.Score)
            .ToList();

        return allScores.Any() ? allScores.Average() : null;
    }

    /// <summary>
    /// Get the stat-card color class based on overall score
    /// </summary>
    private string GetOverallScoreClass()
    {
        var avg = GetOverallAverageScore();
        if (!avg.HasValue) return "stat-card-info";

        return avg.Value switch
        {
            >= 0.8 => "stat-card-success",
            >= 0.5 => "stat-card-warning",
            _ => "stat-card-error"
        };
    }

    /// <summary>
    /// Get the stat-card color class based on a version's score
    /// </summary>
    private static string GetVersionScoreClass(VersionResult vr)
    {
        if (!vr.AvgScore.HasValue) return "stat-card-secondary";

        return vr.AvgScore.Value switch
        {
            >= 0.8 => "stat-card-success",
            >= 0.5 => "stat-card-warning",
            _ => "stat-card-error"
        };
    }

    /// <summary>
    /// Get heatmap-style CSS for cell backgrounds based on score (1-5 scale).
    /// Uses centralized MetricColorHelper for consistent colors across the app.
    /// </summary>
    private static string? GetHeatmapCellStyle(double? score)
    {
        if (!score.HasValue) return null;
        
        var (bgColor, _) = MetricColorHelper.GetScoreColorCss(score.Value);
        return $"background-color: {bgColor}; text-align: center;";
    }

    private async Task ViewCombinedReport()
    {
        _showReportDialog = true;
        _loadingReport = true;
        _reportHtml = null;
        _reportError = null;
        StateHasChanged();

        try
        {
            var url = $"test-case-runs/combined-report?executions={Uri.EscapeDataString(Executions ?? "")}";
            var logger = LoggerFactory.CreateLogger<TestRunComparison>();
            logger.LogInformation("Fetching combined report from: {Url}", url);
            
            var response = await Http.GetAsync(url);
            logger.LogInformation("Response status: {StatusCode}", response.StatusCode);
            
            if (response.IsSuccessStatusCode)
            {
                _reportHtml = await response.Content.ReadAsStringAsync();
            }
            else
            {
                var content = await response.Content.ReadAsStringAsync();
                _reportError = $"Failed to load report: {response.StatusCode}. {content}";
                logger.LogError("Failed to load report: {StatusCode} - {Content}", response.StatusCode, content);
                Snackbar.Add(_reportError, Severity.Error);
            }
        }
        catch (Exception ex)
        {
            var logger = LoggerFactory.CreateLogger<TestRunComparison>();
            logger.LogError(ex, "Failed to load combined report");
            _reportError = $"Error: {ex.Message}";
            Snackbar.Add(_reportError, Severity.Error);
        }
        finally
        {
            _loadingReport = false;
            StateHasChanged();
        }
    }

    private record VersionResult
    {
        public required string ExecutionName { get; init; }
        public required string AgentId { get; init; }
        public required string AgentName { get; init; }
        public required int InstructionVersionId { get; init; }
        public required string VersionNumber { get; init; }
        public List<TestCaseRunResponse> Runs { get; init; } = [];
        public double AvgDuration { get; init; }
        public double? AvgScore { get; init; }
    }

    private record VersionRunPair
    {
        public required VersionResult Version { get; init; }
        public TestCaseRunResponse? Run { get; init; }
    }
}
